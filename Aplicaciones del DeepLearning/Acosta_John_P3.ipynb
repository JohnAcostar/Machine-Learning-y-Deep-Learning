{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Realizado por:\n",
        "1. John Anderson Acosta 202212004"
      ],
      "metadata": {
        "id": "7olGuKX2NJXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar, Cargamos el conjunto de datos de Apple (aapl_features_P3.csv) y luego se selecciona las 8 características las etiquetas, y construimos la ventana de 120 días para el aprendizaje de series temporales."
      ],
      "metadata": {
        "id": "BqbPSLn6VNR0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wt3qtlEhXWO",
        "outputId": "9ee5fbfb-0d2d-4863-ad9c-5d71b1a6ab0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1078, 120, 8) (1078,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv(\"aapl_features_P3.csv\")\n",
        "\n",
        "features = data.drop(columns=[\"y\"]).values\n",
        "labels = data[\"y\"].values\n",
        "\n",
        "window = 120\n",
        "\n",
        "def create_windows(series, labels, window_size):\n",
        "    X, y = [], []\n",
        "    for i in range(len(series) - window_size):\n",
        "        X.append(series[i:i + window_size])\n",
        "        y.append(labels[i + window_size])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_windows(features, labels, window)\n",
        "print(X.shape, y.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Posteriormente, utilizamos el 80 % de los datos para el entrenamiento y el 20 % para las pruebas, manteniendo el orden temporal"
      ],
      "metadata": {
        "id": "JgkC-KvNW--B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n"
      ],
      "metadata": {
        "id": "eS4fF8yv6C13"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego, se construyo el clasificador LSTM siguiendo la arquitectura requerida para los datos de Apple, en el examen fue de un tamaño oculto de 16, 2 capas y dropout de 0,3."
      ],
      "metadata": {
        "id": "ZZl24OsYXJJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMClf(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=16, num_layers=2, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size,\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=num_layers,\n",
        "                            dropout=dropout,\n",
        "                            batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return torch.sigmoid(out)\n"
      ],
      "metadata": {
        "id": "oKidgmNy6FYH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego, Entrenamos el modelo LSTM utilizando el optimizador AdamW y la pérdida de entropía cruzada binaria. La función devuelve la mejor precisión en todas las épocas."
      ],
      "metadata": {
        "id": "bWY8PBY-Xg-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train_lstm(model, X_train, y_train, X_test, y_test, lr, weight_decay, epochs):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    Xtr = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "    ytr = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32).to(device)\n",
        "    Xte = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "    yte = torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32).to(device)\n",
        "\n",
        "    best_acc, best_state = 0, None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(Xtr)\n",
        "        loss = criterion(y_pred, ytr)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                preds = model(Xte)\n",
        "                acc = accuracy_score(y_test, (preds.cpu().numpy() > 0.5).astype(int))\n",
        "            if acc > best_acc:\n",
        "                best_acc = acc\n",
        "                best_state = model.state_dict()\n",
        "            print(f\"Epoch {epoch}: loss={loss.item():.4f}, acc={acc:.4f}\")\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return best_acc\n",
        "\n",
        "model = LSTMClf(input_size=X.shape[2])\n",
        "acc_test = train_lstm(model, X_train, y_train, X_test, y_test,\n",
        "                      lr=5e-3, weight_decay=1e-5, epochs=1000)\n",
        "print(f\" Test Final del Accuracy (APPLE): {acc_test:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYZ2GKQa6HbQ",
        "outputId": "90d28223-cef5-4940-bcfd-24e0df12c318"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss=0.6873, acc=0.5880\n",
            "Epoch 100: loss=0.6603, acc=0.4954\n",
            "Epoch 200: loss=0.6377, acc=0.3889\n",
            "Epoch 300: loss=0.5993, acc=0.4630\n",
            "Epoch 400: loss=0.6076, acc=0.3935\n",
            "Epoch 500: loss=0.5646, acc=0.4306\n",
            "Epoch 600: loss=0.5444, acc=0.4167\n",
            "Epoch 700: loss=0.6053, acc=0.4120\n",
            "Epoch 800: loss=0.6858, acc=0.4120\n",
            "Epoch 900: loss=0.6081, acc=0.6065\n",
            "Epoch 1000: loss=0.6036, acc=0.4120\n",
            " Test Final del Accuracy (APPLE): 0.6065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al observar los resultados, durante el entrenamiento, la pérdida comenzó en 0,6873 y disminuyó gradualmente hasta alrededor de 0,60, mientras que la precisión osciló entre 0,41 y 0,60, estabilizándose finalmente en una precisión de prueba de 0,6065. Este comportamiento indica una convergencia parcial: el modelo fue capaz de reducir su pérdida con el tiempo y mejorar ligeramente la precisión predictiva, pero no logró una convergencia suave o fuerte. Estos resultados son esperables en los datos de series temporales financieras, donde la relación señal-ruido es baja y los rendimientos futuros solo están débilmente correlacionados con los indicadores pasados. el LSTM capturó con éxito algunas dependencias temporales dentro de las ventanas de entrada de 120 días, mostrando un progreso de aprendizaje modesto. Sin embargo, la alta volatilidad de la precisión a lo largo de las épocas sugiere que el modelo podría estar sobreajustadoo con overfitting[1][3]\n",
        "\n",
        "Por último, entrenamos un segundo modelo utilizando únicamente la serie de precios para evaluar el valor añadido de incluir las otras variables."
      ],
      "metadata": {
        "id": "q4j-XhY8Xs5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_price = data[\"price\"].values\n",
        "X_price_w, y_price = create_windows(X_price.reshape(-1,1), labels, window)\n",
        "\n",
        "split = int(len(X_price_w) * 0.8)\n",
        "Xtr_p, Xte_p = X_price_w[:split], X_price_w[split:]\n",
        "ytr_p, yte_p = y_price[:split], y_price[split:]\n",
        "\n",
        "model_price = LSTMClf(input_size=1)\n",
        "acc_test_price = train_lstm(model_price, Xtr_p, ytr_p, Xte_p, yte_p,\n",
        "                            lr=5e-3, weight_decay=1e-5, epochs=1000)\n",
        "\n",
        "print(f\"Test Final del accuracy usando solo el precio: {acc_test_price:.4f}\")\n"
      ],
      "metadata": {
        "id": "_ZV_gBXV6KQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bcf2d24-cc5e-4569-f827-b2599afb648b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss=0.7020, acc=0.4120\n",
            "Epoch 100: loss=0.6703, acc=0.4120\n",
            "Epoch 200: loss=0.6696, acc=0.4120\n",
            "Epoch 300: loss=0.6801, acc=0.5880\n",
            "Epoch 400: loss=0.6695, acc=0.4120\n",
            "Epoch 500: loss=0.6596, acc=0.5880\n",
            "Epoch 600: loss=0.6679, acc=0.4120\n",
            "Epoch 700: loss=0.6690, acc=0.4630\n",
            "Epoch 800: loss=0.6683, acc=0.5556\n",
            "Epoch 900: loss=0.6658, acc=0.4676\n",
            "Test Final del accuracy usando solo el precio: 0.5880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, cuando se volvió a entrenar el LSTM utilizando solo la característica del precio, con los mismos hiperparámetros y estructura de red, la precisión final de la prueba fue de 0,5880. Esta precisión es muy similar al resultado obtenido cuando se incluyeron las ocho características[2].\n",
        "\n",
        "Este resultado demuestra que la mayor parte de la señal predictiva capturada por el LSTM procedía directamente de la propia secuencia de precios sin procesar. La adición de otras variables, como las medias móviles, el impulso o el RSI, aportó poco poder predictivo adicional. Este hallazgo se ajusta al principio de que, en las series temporales financieras, muchos indicadores técnicos son transformaciones derivadas del precio, lo que introduce redundancia en lugar de nueva información.\n",
        "\n",
        "Por ultimo, aunque la inclusión de múltiples características mejoró ligeramente la precisión, la diferencia fue marginal, lo que sugiere que el mecanismo de memoria interna del LSTM ya extrae gran parte de la información necesaria solo del historial de precios. Por lo tanto, la incorporación de variables adicionales podría no justificar la complejidad añadida del modelo, a menos que representen fuentes verdaderamente independientes de información predictiva.\n",
        "\n",
        "**Referencias:**\n",
        "[1] “Advanced stock market Prediction using Long Short-Term Memory Networks: A comprehensive deep learning framework.” https://arxiv.org/html/2505.05325v1\n",
        "\n",
        "[2] A. Rahmadeyan and N. Mustakim, “Long Short-Term memory and gated recurrent unit for stock price prediction,” Procedia Computer Science, vol. 234, pp. 204–212, Jan. 2024, doi: 10.1016/j.procs.2024.02.167.\n",
        "\n",
        "[3]P. Von Stackelberg, L. C. E. Huberts, R. Goedhart, and R. J. M. M. Does, “Multilevel model versus recurrent neural network: A case study to predict student success or failure revisited,” Journal of Quality Technology, pp. 1–20, Jan. 2025, doi: 10.1080/00224065.2024.2435870."
      ],
      "metadata": {
        "id": "Et0N0ptCYH0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#El caso de mordeduras de serpientes"
      ],
      "metadata": {
        "id": "Rcgv4DzVUL09"
      }
    }
  ]
}